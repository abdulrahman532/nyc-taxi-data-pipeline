# ğŸš• NYC Taxi Data Pipeline

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://python.org)
[![dbt](https://img.shields.io/badge/dbt-1.0+-orange.svg)](https://getdbt.com)
[![Airflow](https://img.shields.io/badge/Apache%20Airflow-2.0+-green.svg)](https://airflow.apache.org)
[![Snowflake](https://img.shields.io/badge/Snowflake-Data%20Cloud-29B5E8.svg)](https://snowflake.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

A production-ready **ELT data pipeline** for NYC Yellow Taxi trip data, featuring automated data ingestion from AWS S3, transformation with dbt, and analytics-ready data marts in Snowflake.

## ğŸ“‹ Table of Contents

- [ğŸ¯ Overview](#-overview)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ“Š Data Models](#-data-models)
- [ğŸš€ Setup & Installation](#-setup--installation)
- [ğŸ’» Usage](#-usage)
- [âœ… Data Quality](#-data-quality)
- [ğŸ¤ Contributing](#-contributing)

## ğŸ¯ Overview

This project implements a complete data pipeline that:

- **Extracts** NYC Yellow Taxi trip data from the TLC public dataset
- **Loads** raw Parquet files into Snowflake via AWS S3
- **Transforms** data using dbt with a medallion architecture (staging â†’ intermediate â†’ marts)
- **Orchestrates** workflows with Apache Airflow
- **Delivers** analytics-ready datasets for business intelligence and machine learning

### Key Features

âœ… Incremental data loading with sync state management  
âœ… Data quality tests and validation  
âœ… Dimensional modeling with fact and dimension tables  
âœ… Pre-built analytics for business insights  
âœ… ML-ready feature engineering  
âœ… Infrastructure as Code with AWS Lambda  

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   NYC TLC       â”‚â”€â”€â”€â”€â–¶â”‚    AWS S3       â”‚â”€â”€â”€â”€â–¶â”‚   Snowflake     â”‚
â”‚   Open Data     â”‚     â”‚   Raw Storage   â”‚     â”‚   Data Cloud    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                               â”‚                        â”‚
                               â–¼                        â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚     dbt     â”‚          â”‚   Airflow   â”‚
                        â”‚ Transforms  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Orchestr  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼                   â–¼                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Staging    â”‚â”€â”€â”€â”€â–¶â”‚Intermediate â”‚â”€â”€â”€â”€â–¶â”‚    Marts    â”‚
    â”‚   Layer     â”‚     â”‚   Layer     â”‚     â”‚   Layer     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
nyc-taxi-data-pipeline/
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â”œâ”€â”€ deploy_infrastructure_dag.py  # Infrastructure deployment
â”‚       â”œâ”€â”€ nyc_taxi_sync_dag.py          # Main data sync DAG
â”‚       â””â”€â”€ scripts/
â”‚           â””â”€â”€ sync_manager.py           # Sync state management
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ deploy_lambda.py                  # Lambda deployment script
â”‚   â””â”€â”€ lambda_function.py                # S3 data ingestion Lambda
â”œâ”€â”€ nyc_taxi_dbt/
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/                      # Raw data cleaning
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_trips.sql
â”‚   â”‚   â”‚   â””â”€â”€ stg_taxi_zones.sql
â”‚   â”‚   â”œâ”€â”€ intermediate/                 # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ int_trips_cleaned.sql
â”‚   â”‚   â”‚   â””â”€â”€ int_trips_enriched.sql
â”‚   â”‚   â””â”€â”€ marts/
â”‚   â”‚       â”œâ”€â”€ core/                     # Dimensional models
â”‚   â”‚       â”‚   â”œâ”€â”€ fct_trips.sql
â”‚   â”‚       â”‚   â”œâ”€â”€ dim_zones.sql
â”‚   â”‚       â”‚   â”œâ”€â”€ dim_vendors.sql
â”‚   â”‚       â”‚   â”œâ”€â”€ dim_payment_types.sql
â”‚   â”‚       â”‚   â””â”€â”€ dim_rate_codes.sql
â”‚   â”‚       â”œâ”€â”€ aggregations/             # Pre-aggregated metrics
â”‚   â”‚       â”‚   â”œâ”€â”€ agg_monthly_overview.sql
â”‚   â”‚       â”‚   â””â”€â”€ agg_monthly_by_borough.sql
â”‚   â”‚       â”œâ”€â”€ insights/                 # Business analytics
â”‚   â”‚       â”‚   â”œâ”€â”€ insight_covid_recovery.sql
â”‚   â”‚       â”‚   â”œâ”€â”€ insight_congestion_pricing_impact.sql
â”‚   â”‚       â”‚   â””â”€â”€ insight_industry_evolution.sql
â”‚   â”‚       â””â”€â”€ ml_features/              # ML feature store
â”‚   â”‚           â”œâ”€â”€ ml_trip_features.sql
â”‚   â”‚           â””â”€â”€ ml_customer_segments.sql
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ download_zone_lookup.py           # Zone data download
â”œâ”€â”€ snowflake/
â”‚   â””â”€â”€ setup.sql                         # Snowflake infrastructure
â””â”€â”€ README.md
```

## ğŸ“Š Data Models

### Staging Layer
| Model | Description |
|-------|-------------|
| `stg_trips` | Cleaned raw trip records with standardized column names |
| `stg_taxi_zones` | NYC taxi zone reference data |

### Intermediate Layer
| Model | Description |
|-------|-------------|
| `int_trips_cleaned` | Filtered trips with data quality rules applied |
| `int_trips_enriched` | Trips enriched with zone and temporal attributes |

### Marts Layer

#### Core (Dimensional Model)
| Model | Type | Description |
|-------|------|-------------|
| `fct_trips` | Fact | Core trip transactions with metrics |
| `dim_zones` | Dimension | Pickup/dropoff location attributes |
| `dim_vendors` | Dimension | Taxi vendor information |
| `dim_payment_types` | Dimension | Payment method lookup |
| `dim_rate_codes` | Dimension | Rate code descriptions |

#### Aggregations
| Model | Description |
|-------|-------------|
| `agg_monthly_overview` | Monthly KPIs: trips, revenue, avg fare |
| `agg_monthly_by_borough` | Borough-level monthly metrics |

#### Insights
| Model | Description |
|-------|-------------|
| `insight_covid_recovery` | COVID-19 impact and recovery analysis |
| `insight_congestion_pricing_impact` | Manhattan congestion pricing effects |
| `insight_industry_evolution` | Long-term industry trends (2013-present) |

#### ML Features
| Model | Description |
|-------|-------------|
| `ml_trip_features` | Feature vectors for trip prediction models |
| `ml_customer_segments` | Customer segmentation features |

## ğŸš€ Setup & Installation

### Prerequisites

- Python 3.9+
- Snowflake account
- AWS account (for S3 storage)
- Apache Airflow 2.0+

### 1. Clone the Repository

```bash
git clone https://github.com/abdulrahman532/nyc-taxi-data-pipeline.git
cd nyc-taxi-data-pipeline
```

### 2. Set Up Python Environment

```bash
python -m venv dbt_venv
source dbt_venv/bin/activate
pip install dbt-snowflake apache-airflow boto3
```

### 3. Configure Snowflake

Run the setup script in Snowflake:

```sql
-- Execute snowflake/setup.sql in Snowflake Worksheets
```

### 4. Configure dbt Profile

Create `~/.dbt/profiles.yml`:

```yaml
nyc_taxi:
  target: dev
  outputs:
    dev:
      type: snowflake
      account: <your_account>
      user: <your_user>
      password: <your_password>
      role: DATA_ENGINEER
      database: NYC_TAXI_DB
      warehouse: TAXI_WH
      schema: RAW
      threads: 4
```

### 5. Install dbt Packages

```bash
cd nyc_taxi_dbt
dbt deps
```

## ğŸ’» Usage

### Run dbt Models

```bash
cd nyc_taxi_dbt

# Run all models
dbt run

# Run specific layer
dbt run --select staging
dbt run --select intermediate
dbt run --select marts

# Run with tests
dbt build
```

### Run Data Tests

```bash
dbt test
```

### Generate Documentation

```bash
dbt docs generate
dbt docs serve
```

### Trigger Airflow DAGs

```bash
# Via Airflow CLI
airflow dags trigger nyc_taxi_sync_dag

# Or use the Airflow Web UI
```

## âœ… Data Quality

The pipeline includes comprehensive data quality checks:

- **Schema Tests**: Not null, unique, accepted values
- **Freshness Tests**: Data recency monitoring
- **Custom Tests**: Business rule validation
- **Row Count Validation**: Source-to-target reconciliation

## ğŸ“ˆ Sample Queries

### Monthly Revenue Trend
```sql
SELECT * FROM NYC_TAXI_DB.MARTS.AGG_MONTHLY_OVERVIEW
ORDER BY year, month;
```

### Top Pickup Locations
```sql
SELECT 
    pickup_zone,
    pickup_borough,
    COUNT(*) as trip_count,
    SUM(total_amount) as total_revenue
FROM NYC_TAXI_DB.MARTS.FCT_TRIPS
GROUP BY 1, 2
ORDER BY trip_count DESC
LIMIT 10;
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [NYC Taxi & Limousine Commission](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) for the open dataset
- [dbt Labs](https://www.getdbt.com/) for the amazing transformation framework
- [Snowflake](https://www.snowflake.com/) for the cloud data platform

---

**Built with â¤ï¸ by [Abdulrahman](https://github.com/abdulrahman532)**