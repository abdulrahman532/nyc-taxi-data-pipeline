# üöï NYC Taxi Data Pipeline

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://python.org)
[![dbt](https://img.shields.io/badge/dbt-1.0+-orange.svg)](https://getdbt.com)
[![Airflow](https://img.shields.io/badge/Apache%20Airflow-2.0+-green.svg)](https://airflow.apache.org)
[![Snowflake](https://img.shields.io/badge/Snowflake-Data%20Cloud-29B5E8.svg)](https://snowflake.com)
[![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-Streaming-231F20.svg)](https://kafka.apache.org)
[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-Streaming-E25A1C.svg)](https://spark.apache.org)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

A production-ready **ELT data pipeline** for NYC Yellow Taxi trip data, featuring automated batch data ingestion from AWS S3, **real-time streaming with fraud detection**, transformation with dbt, and analytics-ready data marts in Snowflake.

## üìã Table of Contents

- [üéØ Overview](#-overview)
- [üèóÔ∏è Architecture](#Ô∏è-architecture)
- [üìÅ Project Structure](#-project-structure)
- [üìä Data Models](#-data-models)
- [üì° Real-Time Streaming](#-real-time-streaming)
- [üöÄ Setup & Installation](#-setup--installation)
- [üíª Usage](#-usage)
- [‚úÖ Data Quality](#-data-quality)
- [ü§ù Contributing](#-contributing)

## üéØ Overview

This project implements a complete **batch + real-time** data pipeline that:

- **Extracts** NYC Yellow Taxi trip data from the TLC public dataset
- **Loads** raw Parquet files into Snowflake via AWS S3
- **Transforms** data using dbt with a medallion architecture (staging ‚Üí intermediate ‚Üí marts)
- **Streams** real-time trip data through Kafka with Spark Streaming
- **Detects** fraudulent trips in real-time using custom rules
- **Orchestrates** batch workflows with Apache Airflow
- **Delivers** analytics-ready datasets for business intelligence

### Key Features

‚úÖ Incremental data loading with sync state management  
‚úÖ **Real-time streaming pipeline with Apache Kafka & Spark**  
‚úÖ **Fraud detection system with 15+ detection rules**  
‚úÖ **Live dashboard with Streamlit for real-time monitoring**  
‚úÖ Data quality tests and validation  
‚úÖ One Big Table (OBT) for simplified analytics  
‚úÖ 11 pre-built business insights ready for visualization  
‚úÖ Infrastructure as Code with AWS Lambda  

## üèóÔ∏è Architecture

### Batch Pipeline

```mermaid
flowchart LR
    A[üåê NYC TLC\nOpen Data] --> B[‚òÅÔ∏è AWS S3\nRaw Storage]
    B --> C[‚ùÑÔ∏è Snowflake\nData Cloud]
    C --> D[üîÑ dbt\nTransforms]
    C --> E[‚è∞ Airflow\nOrchestration]
    D <--> E
    D --> F[üì• Staging]
    F --> G[üîß Intermediate]
    G --> H[üìä Marts]
```

### Real-Time Streaming Pipeline

```mermaid
flowchart LR
    A[üöï Taxi App] --> B[‚ö° FastAPI\nWebhook]
    B --> C[üì® Kafka\nBroker]
    C --> D[üî• Spark\nStreaming]
    D --> E[üíæ Redis\nCache]
    E --> F[üìà Streamlit\nDashboard]
```

## üìÅ Project Structure

\`\`\`
nyc-taxi-data-pipeline/
‚îú‚îÄ‚îÄ airflow/
‚îÇ   ‚îî‚îÄ‚îÄ dags/
‚îÇ       ‚îú‚îÄ‚îÄ deploy_infrastructure_dag.py
‚îÇ       ‚îú‚îÄ‚îÄ nyc_taxi_sync_dag.py
‚îÇ       ‚îî‚îÄ‚îÄ scripts/
‚îÇ           ‚îî‚îÄ‚îÄ sync_manager.py
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îú‚îÄ‚îÄ deploy_lambda.py
‚îÇ   ‚îî‚îÄ‚îÄ lambda_function.py
‚îú‚îÄ‚îÄ nyc_taxi_dbt/
‚îÇ   ‚îú‚îÄ‚îÄ dbt_project.yml
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ staging/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_trips.sql
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stg_zones.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ intermediate/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ int_trips_validated.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ marts/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ obt_trips.sql
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dim_zones.sql
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dim_payment_types.sql
‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ dim_rate_codes.sql
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ aggregations/
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ agg_monthly.sql
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ agg_quarterly.sql
‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ agg_yearly.sql
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ insights/
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ insight_uber_effect.sql
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ insight_covid_recovery.sql
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ insight_airport_lifeline.sql
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ insight_payment_shift.sql
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ insight_manhattan_share.sql
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ insight_tipping_patterns.sql
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ insight_route_pricing.sql
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ insight_fee_impact.sql
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ insight_zone_heatmap.sql
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ insight_anomaly_breakdown.sql
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ insight_industry_evolution.sql
‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îÇ       ‚îú‚îÄ‚îÄ assert_pickup_before_dropoff.sql
‚îÇ       ‚îú‚îÄ‚îÄ assert_positive_fares.sql
‚îÇ       ‚îú‚îÄ‚îÄ assert_valid_speed.sql
‚îÇ       ‚îî‚îÄ‚îÄ assert_valid_trip_duration.sql
‚îú‚îÄ‚îÄ streaming/
‚îÇ   ‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kafka_producer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ spark/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fraud_detector.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1_üìä_Live_Overview.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 2_üïµÔ∏è_Fraud_Detection.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ simulator/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ send_trips.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ download_zone_lookup.py
‚îú‚îÄ‚îÄ snowflake/
‚îÇ   ‚îî‚îÄ‚îÄ setup.sql
‚îî‚îÄ‚îÄ README.md
\`\`\`

## üìä Data Models

### Snowflake Database Structure
\`\`\`
NYC_TAXI_DB
‚îÇ
‚îú‚îÄ‚îÄ RAW_staging (Views)
‚îÇ   ‚îú‚îÄ‚îÄ stg_trips
‚îÇ   ‚îî‚îÄ‚îÄ stg_zones
‚îÇ
‚îú‚îÄ‚îÄ RAW_intermediate (Views)
‚îÇ   ‚îî‚îÄ‚îÄ int_trips_validated
‚îÇ
‚îú‚îÄ‚îÄ RAW_marts (Tables)
‚îÇ   ‚îú‚îÄ‚îÄ dim_zones              ‚Üê Dimension
‚îÇ   ‚îú‚îÄ‚îÄ dim_payment_types      ‚Üê Dimension
‚îÇ   ‚îú‚îÄ‚îÄ dim_rate_codes         ‚Üê Dimension
‚îÇ   ‚îú‚îÄ‚îÄ obt_trips              ‚Üê One Big Table (Denormalized)
‚îÇ   ‚îú‚îÄ‚îÄ agg_monthly            ‚Üê Aggregated
‚îÇ   ‚îú‚îÄ‚îÄ agg_quarterly          ‚Üê Aggregated
‚îÇ   ‚îî‚îÄ‚îÄ agg_yearly             ‚Üê Aggregated
‚îÇ
‚îî‚îÄ‚îÄ RAW_insights (Tables - Ready for Visualization)
    ‚îú‚îÄ‚îÄ insight_uber_effect
    ‚îú‚îÄ‚îÄ insight_covid_recovery
    ‚îú‚îÄ‚îÄ insight_airport_lifeline
    ‚îú‚îÄ‚îÄ insight_payment_shift
    ‚îú‚îÄ‚îÄ insight_manhattan_share
    ‚îú‚îÄ‚îÄ insight_tipping_patterns
    ‚îú‚îÄ‚îÄ insight_route_pricing
    ‚îú‚îÄ‚îÄ insight_fee_impact
    ‚îú‚îÄ‚îÄ insight_zone_heatmap
    ‚îú‚îÄ‚îÄ insight_anomaly_breakdown
    ‚îî‚îÄ‚îÄ insight_industry_evolution
\`\`\`

### Staging Layer (Views)
| Model | Description |
|-------|-------------|
| \`stg_trips\` | Cleaned raw trip records with standardized column names |
| \`stg_zones\` | NYC taxi zone reference data |

### Intermediate Layer (Views)
| Model | Description |
|-------|-------------|
| \`int_trips_validated\` | Trips with data quality validation and filtering |

### Marts Layer (Tables)

#### Dimensions
| Model | Description |
|-------|-------------|
| \`dim_zones\` | Pickup/dropoff location attributes |
| \`dim_payment_types\` | Payment method lookup |
| \`dim_rate_codes\` | Rate code descriptions |

#### One Big Table
| Model | Description |
|-------|-------------|
| \`obt_trips\` | Denormalized table with all trip data for easy analytics |

#### Aggregations
| Model | Description |
|-------|-------------|
| \`agg_monthly\` | Monthly KPIs: trips, revenue, avg fare, tips |
| \`agg_quarterly\` | Quarterly performance metrics |
| \`agg_yearly\` | Yearly trends and YoY comparisons |

### Insights Layer (Tables - Ready for Visualization)
| Model | Description |
|-------|-------------|
| \`insight_uber_effect\` | Impact of rideshare competition |
| \`insight_covid_recovery\` | COVID-19 impact and recovery analysis |
| \`insight_airport_lifeline\` | Airport trip importance analysis |
| \`insight_payment_shift\` | Cash to card payment transition |
| \`insight_manhattan_share\` | Manhattan vs outer borough trends |
| \`insight_tipping_patterns\` | Tipping behavior analysis |
| \`insight_route_pricing\` | Popular route pricing patterns |
| \`insight_fee_impact\` | Congestion surcharge and fee analysis |
| \`insight_zone_heatmap\` | Pickup/dropoff zone activity |
| \`insight_anomaly_breakdown\` | Data quality anomaly detection |
| \`insight_industry_evolution\` | Long-term industry trends (2009-present) |

## üì° Real-Time Streaming

The streaming module provides real-time taxi trip processing with fraud detection.

### Components
- **FastAPI Server**: Webhook receiver for incoming trips
- **Apache Kafka**: Message broker for trip events
- **Spark Streaming**: Real-time fraud detection engine
- **Redis**: Metrics caching layer
- **Streamlit Dashboard**: Live monitoring UI

### Fraud Detection Rules
The system detects fraud using 15+ rules including:
- Impossible speed (> 100 mph)
- Zero distance with fare
- Tip exceeds fare amount
- Fake airport fees
- Night cash trip patterns
- And more...

### Quick Start
\`\`\`bash
# Start infrastructure
cd streaming/docker && docker-compose up -d

# Start API server
cd streaming/api && uvicorn main:app --port 8000

# Start Spark fraud detector
cd streaming/spark && spark-submit fraud_detector.py

# Start dashboard
cd streaming/dashboard && streamlit run app.py
\`\`\`

See [streaming/README.md](streaming/README.md) for detailed documentation.

## üöÄ Setup & Installation

### Prerequisites

- Python 3.9+
- Snowflake account
- AWS account (for S3 storage)
- Apache Airflow 2.0+
- Docker (for streaming)

### 1. Clone the Repository

\`\`\`bash
git clone https://github.com/abdulrahman532/nyc-taxi-data-pipeline.git
cd nyc-taxi-data-pipeline
\`\`\`

### 2. Set Up Python Environment

\`\`\`bash
python -m venv dbt_venv
source dbt_venv/bin/activate
pip install dbt-snowflake apache-airflow boto3
\`\`\`

### 3. Configure Snowflake

Run the setup script in Snowflake:

\`\`\`sql
-- Execute snowflake/setup.sql in Snowflake Worksheets
\`\`\`

### 4. Configure dbt Profile

Create \`~/.dbt/profiles.yml\`:

\`\`\`yaml
nyc_taxi:
  target: dev
  outputs:
    dev:
      type: snowflake
      account: <your_account>
      user: <your_user>
      password: <your_password>
      role: DATA_ENGINEER
      database: NYC_TAXI_DB
      warehouse: TAXI_WH
      schema: RAW
      threads: 4
\`\`\`

### 5. Install dbt Packages

\`\`\`bash
cd nyc_taxi_dbt
dbt deps
\`\`\`

## üíª Usage

### Run dbt Models

\`\`\`bash
cd nyc_taxi_dbt

# Run all models
dbt run

# Run specific layer
dbt run --select staging
dbt run --select intermediate
dbt run --select marts

# Run only insights
dbt run --select insights

# Run with tests
dbt build
\`\`\`

### Run Data Tests

\`\`\`bash
dbt test
\`\`\`

### Generate Documentation

\`\`\`bash
dbt docs generate
dbt docs serve
\`\`\`

### Trigger Airflow DAGs

\`\`\`bash
# Via Airflow CLI
airflow dags trigger nyc_taxi_sync_dag

# Or use the Airflow Web UI
\`\`\`

## ‚úÖ Data Quality

The pipeline includes comprehensive data quality checks:

### Schema Tests
- Not null constraints
- Unique keys validation
- Accepted values checks

### Custom Tests
| Test | Description |
|------|-------------|
| \`assert_pickup_before_dropoff\` | Validates pickup time < dropoff time |
| \`assert_positive_fares\` | Ensures fares are positive |
| \`assert_valid_speed\` | Checks for reasonable trip speeds |
| \`assert_valid_trip_duration\` | Validates trip duration range |

## üìà Sample Queries

### Monthly Revenue Trend
\`\`\`sql
SELECT * FROM NYC_TAXI_DB.MARTS.AGG_MONTHLY
ORDER BY year, month;
\`\`\`

### COVID Recovery Analysis
\`\`\`sql
SELECT * FROM NYC_TAXI_DB.MARTS.INSIGHT_COVID_RECOVERY
ORDER BY year, month;
\`\`\`

### Top Pickup Locations
\`\`\`sql
SELECT 
    pickup_zone,
    pickup_borough,
    COUNT(*) as trip_count,
    SUM(total_amount) as total_revenue
FROM NYC_TAXI_DB.MARTS.OBT_TRIPS
GROUP BY 1, 2
ORDER BY trip_count DESC
LIMIT 10;
\`\`\`

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (\`git checkout -b feature/amazing-feature\`)
3. Commit your changes (\`git commit -m 'Add amazing feature'\`)
4. Push to the branch (\`git push origin feature/amazing-feature\`)
5. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- [NYC Taxi & Limousine Commission](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) for the open dataset
- [dbt Labs](https://www.getdbt.com/) for the amazing transformation framework
- [Snowflake](https://www.snowflake.com/) for the cloud data platform

---

**Built with ‚ù§Ô∏è by [Abdulrahman](https://github.com/abdulrahman532)**
