# ğŸ” ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ§Ù„Ø¥ØµÙ„Ø§Ø­Ø§Øª - NYC Taxi Data Pipeline

> ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ‚Ø±ÙŠØ±: 1 Ø¯ÙŠØ³Ù…Ø¨Ø± 2025

---

## ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª

1. [Ø£Ø®Ø·Ø§Ø¡ Ù…Ù„ÙØ§Øª SQL](#-Ø£Ø®Ø·Ø§Ø¡-Ù…Ù„ÙØ§Øª-sql)
2. [Ù…Ø´Ø§ÙƒÙ„ Docker Ùˆ Ø§Ù„ØªØ´ØºÙŠÙ„](#-Ù…Ø´Ø§ÙƒÙ„-docker-ÙˆØ§Ù„ØªØ´ØºÙŠÙ„)
3. [Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„](#-Ø¯Ù„ÙŠÙ„-Ø§Ù„ØªØ´ØºÙŠÙ„-Ø§Ù„ÙƒØ§Ù…Ù„)

---

## ğŸ—„ï¸ Ø£Ø®Ø·Ø§Ø¡ Ù…Ù„ÙØ§Øª SQL

### âŒ Ø®Ø·Ø£ 1: Ø®Ø·Ø£ ÙÙŠ Syntax - Ù…Ù„Ù `insight_zone_heatmap.sql`

**Ø§Ù„Ù…Ù„Ù:** `nyc_taxi_dbt/models/marts/insights/insight_zone_heatmap.sql`

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** Ù‚ÙˆØ³ Ù…ÙÙ‚ÙˆØ¯ ÙÙŠ Ø§Ù„Ù€ `CASE WHEN` statement ÙÙŠ Ø§Ù„Ø³Ø·Ø± 28

```sql
-- âŒ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø®Ø§Ø·Ø¦:
case
    when percent_rank() over (order by coalesce(p.pickup_count, 0) desc) >= 0.95 then 'Very Hot'
    when percent_rank() over (order by coalesce(p.pickup_count, 0) >= 0.80 then 'Hot'  -- â† Ù‚ÙˆØ³ Ù…ÙÙ‚ÙˆØ¯ Ù‡Ù†Ø§!
    when percent_rank() over (order by coalesce(p.pickup_count, 0)) >= 0.50 then 'Warm'
    else 'Cold'
end as heat_level,
```

**Ø§Ù„Ø¥ØµÙ„Ø§Ø­:**
```sql
-- âœ… Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ØµØ­ÙŠØ­:
case
    when percent_rank() over (order by coalesce(p.pickup_count, 0) desc) >= 0.95 then 'Very Hot'
    when percent_rank() over (order by coalesce(p.pickup_count, 0) desc) >= 0.80 then 'Hot'  -- â† ØªÙ… Ø¥Ø¶Ø§ÙØ© `) desc`
    when percent_rank() over (order by coalesce(p.pickup_count, 0) desc) >= 0.50 then 'Warm'  -- â† ØªÙ… Ø¥Ø¶Ø§ÙØ© `desc`
    else 'Cold'
end as heat_level,
```

**Ø§Ù„Ø³Ø¨Ø¨:** Ø§Ù„Ù‚ÙˆØ³ Ø§Ù„Ù…ØºÙ„Ù‚ Ù…ÙÙ‚ÙˆØ¯ Ø¨Ø¹Ø¯ `pickup_count, 0)` ÙˆÙƒÙ„Ù…Ø© `desc` Ù…ÙÙ‚ÙˆØ¯Ø© Ø£ÙŠØ¶Ø§Ù‹

---

### âš ï¸ Ø®Ø·Ø£ 2: Ù…Ø´ÙƒÙ„Ø© Logic - Ù…Ù„Ù `stg_trips.sql`

**Ø§Ù„Ù…Ù„Ù:** `nyc_taxi_dbt/models/staging/stg_trips.sql`

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** Ø¹Ø¯Ù… ØªØ·Ø§Ø¨Ù‚ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ÙŠÙ† `pickup_datetime_raw` Ùˆ `dropoff_datetime_raw`

```sql
-- âŒ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ:
left(date_part(epoch_nanosecond, tpep_pickup_datetime)::varchar, 16)::bigint as pickup_datetime_raw,
tpep_dropoff_datetime as dropoff_datetime_raw,  -- â† Ù‡Ø°Ø§ timestamp ÙˆÙ„ÙŠØ³ bigint!
```

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** 
- `pickup_datetime_raw` ÙŠØªÙ… ØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ `bigint` (epoch nanoseconds)
- `dropoff_datetime_raw` ÙŠØ¨Ù‚Ù‰ ÙƒÙ€ `timestamp` 

Ù‡Ø°Ø§ ÙŠØ³Ø¨Ø¨ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ `int_trips_validated.sql` Ø­ÙŠØ« ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…:
```sql
to_timestamp(pickup_datetime_raw / 1000000) as pickup_datetime,
to_timestamp(dropoff_datetime_raw / 1000000) as dropoff_datetime,  -- â† Ø³ÙŠÙØ´Ù„!
```

**Ø§Ù„Ø¥ØµÙ„Ø§Ø­:**
```sql
-- âœ… Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ØµØ­ÙŠØ­:
left(date_part(epoch_nanosecond, tpep_pickup_datetime)::varchar, 16)::bigint as pickup_datetime_raw,
left(date_part(epoch_nanosecond, tpep_dropoff_datetime)::varchar, 16)::bigint as dropoff_datetime_raw,
```

---

### âš ï¸ Ø®Ø·Ø£ 3: Ù…Ø´ÙƒÙ„Ø© Logic - Ù…Ù„Ù `int_trips_validated.sql`

**Ø§Ù„Ù…Ù„Ù:** `nyc_taxi_dbt/models/intermediate/int_trips_validated.sql`

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø© 1:** Ø§Ø³ØªØ®Ø¯Ø§Ù… `pickup_datetime` Ùˆ `dropoff_datetime` Ù‚Ø¨Ù„ ØªØ¹Ø±ÙŠÙÙ‡Ù… ÙÙŠ Ø§Ù„Ù€ WHERE clause

```sql
-- âŒ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø®Ø§Ø·Ø¦:
from source
where pickup_datetime is not null  -- â† Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù… ØªÙØ¹Ø±Ù Ø¨Ø¹Ø¯ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©!
  and dropoff_datetime is not null
  and dropoff_datetime >= pickup_datetime
```

**Ø§Ù„Ø¥ØµÙ„Ø§Ø­:**
```sql
-- âœ… Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ØµØ­ÙŠØ­:
from source
where pickup_datetime_raw is not null
  and dropoff_datetime_raw is not null
  and dropoff_datetime_raw >= pickup_datetime_raw
```

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø© 2:** Ø§Ø³ØªØ®Ø¯Ø§Ù… `trip_duration_minutes` Ù‚Ø¨Ù„ ØªØ¹Ø±ÙŠÙÙ‡ ÙÙŠ Ø§Ù„Ù€ `enhanced` CTE

```sql
-- âŒ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø®Ø§Ø·Ø¦ (ÙÙŠ enhanced CTE):
case when trip_duration_minutes > 0  -- â† Ù„Ù… ÙŠÙØ¹Ø±Ù Ø¨Ø¹Ø¯ ÙÙŠ Ù†ÙØ³ SELECT!
     then trip_distance / (trip_duration_minutes / 60.0) 
     end as speed_mph,
```

**Ø§Ù„Ø¥ØµÙ„Ø§Ø­:** ÙŠØ¬Ø¨ Ù†Ù‚Ù„ Ø­Ø³Ø§Ø¨ `speed_mph` Ø¥Ù„Ù‰ CTE Ù…Ù†ÙØµÙ„ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±:

```sql
-- âœ… Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ØµØ­ÙŠØ­:
case when datediff('minute', pickup_datetime, dropoff_datetime) > 0 
     then trip_distance / (datediff('minute', pickup_datetime, dropoff_datetime) / 60.0) 
     end as speed_mph,
```

---

### âš ï¸ Ø®Ø·Ø£ 4: Ù…Ø´ÙƒÙ„Ø© Logic - Ù…Ù„Ù `obt_trips.sql`

**Ø§Ù„Ù…Ù„Ù:** `nyc_taxi_dbt/models/marts/core/obt_trips.sql`

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** Ø§Ù„Ù€ view ÙŠØ³ØªØ®Ø¯Ù… Ø£Ø¹Ù…Ø¯Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ `fct_trips`

```sql
-- âŒ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙˆÙ„ÙƒÙ† ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ fct_trips:
f.is_suspicious_zero_distance
f.is_zero_distance_high_fare
f.is_refund
f.is_extreme_speed
f.tip_percentage
```

Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ `int_trips_validated` ÙˆÙ„ÙƒÙ† Ù„Ù… ÙŠØªÙ… Ù†Ù‚Ù„Ù‡Ø§ Ø¥Ù„Ù‰ `fct_trips`.

**Ø§Ù„Ø¥ØµÙ„Ø§Ø­:** Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø¥Ù„Ù‰ `fct_trips.sql`:

```sql
-- âœ… Ø¥Ø¶Ø§ÙØ© ÙÙŠ fct_trips.sql:
select
    trip_id,
    -- ... Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© ...
    tip_percentage,
    time_of_day,
    day_type,
    is_suspicious_zero_distance,
    is_zero_distance_high_fare,
    is_refund,
    is_extreme_fare,
    is_extreme_speed,
    speed_mph,
    fare_per_mile
from trips
```

---

### âš ï¸ Ø®Ø·Ø£ 5: Ù…Ø´ÙƒÙ„Ø© Logic - Ù…Ù„Ù `agg_yearly.sql`

**Ø§Ù„Ù…Ù„Ù:** `nyc_taxi_dbt/models/marts/aggregations/agg_yearly.sql`

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** Ø§Ù„Ø¹Ù…ÙˆØ¯ `airport_trips` Ù…ÙÙ‚ÙˆØ¯ Ù„ÙƒÙ† `insight_airport_lifeline.sql` ÙŠØ³ØªØ®Ø¯Ù…Ù‡

```sql
-- ÙÙŠ insight_airport_lifeline.sql:
airport_trips,  -- â† Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù…ÙˆØ¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ agg_yearly!
```

**Ø§Ù„Ø¥ØµÙ„Ø§Ø­:** Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù…ÙˆØ¯ ÙÙŠ `agg_yearly.sql`:

```sql
-- âœ… Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ØµØ­ÙŠØ­:
select
    pickup_year,
    sum(total_trips) as total_trips,
    sum(airport_trips) as airport_trips,  -- â† Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø±
    -- ... Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ...
```

---

### âš ï¸ Ø®Ø·Ø£ 6: Ù…Ø´ÙƒÙ„Ø© Logic - Ù…Ù„Ù `agg_yearly.sql`

**Ø§Ù„Ù…Ù„Ù:** `nyc_taxi_dbt/models/marts/aggregations/agg_yearly.sql`

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** Ø§Ù„Ø¹Ù…ÙˆØ¯ `trips_yoy_pct` Ù…ÙÙ‚ÙˆØ¯ Ù„ÙƒÙ† `insight_industry_evolution.sql` ÙŠØ³ØªØ®Ø¯Ù…Ù‡

```sql
-- ÙÙŠ insight_industry_evolution.sql:
trips_yoy_pct,  -- â† Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù…ÙˆØ¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ agg_yearly!
```

**Ø§Ù„Ø¥ØµÙ„Ø§Ø­:** Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù…ÙˆØ¯ ÙÙŠ `agg_yearly.sql`:

```sql
-- âœ… Ø¥Ø¶Ø§ÙØ© Ø­Ø³Ø§Ø¨ Year-over-Year:
select
    pickup_year,
    sum(total_trips) as total_trips,
    round(
        (sum(total_trips) - lag(sum(total_trips)) over (order by pickup_year)) 
        * 100.0 / nullif(lag(sum(total_trips)) over (order by pickup_year), 0), 
        2
    ) as trips_yoy_pct,
    -- ... Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ...
```

---

### âš ï¸ Ø®Ø·Ø£ 7: Ù…Ø´ÙƒÙ„Ø© Logic - Ù…Ù„Ù `agg_monthly.sql`

**Ø§Ù„Ù…Ù„Ù:** `nyc_taxi_dbt/models/marts/aggregations/agg_monthly.sql`

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙŠ `insight_fee_impact.sql` Ù„ÙƒÙ†Ù‡Ø§ Ù…ÙÙ‚ÙˆØ¯Ø©:
- `congestion_revenue`
- `airport_fee_revenue`
- `cbd_fee_revenue`

**Ø§Ù„Ø¥ØµÙ„Ø§Ø­:** Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙÙŠ `agg_monthly.sql`:

```sql
-- âœ… Ø¥Ø¶Ø§ÙØ©:
round(sum(congestion_surcharge), 2) as congestion_revenue,
round(sum(airport_fee), 2) as airport_fee_revenue,
round(sum(cbd_congestion_fee), 2) as cbd_fee_revenue,
```

---

### âš ï¸ Ø®Ø·Ø£ 8: Ù…Ø´ÙƒÙ„Ø© Logic - Ù…Ù„Ù `dim_date.sql`

**Ø§Ù„Ù…Ù„Ù:** `nyc_taxi_dbt/models/marts/core/dim_date.sql`

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© `dayofweek()` Ù…Ø¹ Ù‚ÙŠÙ… ØºÙŠØ± ØµØ­ÙŠØ­Ø©

```sql
-- âŒ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø®Ø§Ø·Ø¦:
case when dayofweek(date_id) in (0, 6) then false else true end as is_weekday,
case when dayofweek(date_id) in (0, 6) then true else false end as is_weekend,
```

**Ù…Ù„Ø§Ø­Ø¸Ø©:** ÙÙŠ SnowflakeØŒ `dayofweek()` ØªØ±Ø¬Ø¹:
- 0 = Ø§Ù„Ø£Ø­Ø¯ (Sunday)
- 1 = Ø§Ù„Ø§Ø«Ù†ÙŠÙ† (Monday)
- ...
- 6 = Ø§Ù„Ø³Ø¨Øª (Saturday)

Ù„ÙƒÙ† ÙÙŠ Ø¨Ø¹Ø¶ Ø£Ù†Ø¸Ù…Ø© SQL Ø§Ù„Ø£Ø®Ø±Ù‰ØŒ Ø§Ù„Ù‚ÙŠÙ… Ù…Ø®ØªÙ„ÙØ©. ØªØ£ÙƒØ¯ Ù…Ù† ØªÙˆØ§ÙÙ‚ Ø§Ù„Ù‚ÙŠÙ… Ù…Ø¹ Snowflake.

---

### âš ï¸ Ø®Ø·Ø£ 9: Ù…Ø´ÙƒÙ„Ø© Logic - Ù…Ù„Ù `assert_positive_fares.sql`

**Ø§Ù„Ù…Ù„Ù:** `nyc_taxi_dbt/tests/assert_positive_fares.sql`

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** Ø§Ø³Ù… Ø§Ù„Ù€ test Ù…Ø¶Ù„Ù„ - ÙŠÙ‚ÙˆÙ„ "positive fares" Ù„ÙƒÙ† ÙŠØ³Ù…Ø­ Ø¨Ù‚ÙŠÙ… Ø­ØªÙ‰ -100

```sql
-- âŒ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ:
where fare_amount < -100  -- â† ÙŠØ³Ù…Ø­ Ø¨Ù‚ÙŠÙ… Ø³Ø§Ù„Ø¨Ø© Ø­ØªÙ‰ -100!
```

**Ø§Ù„ØªÙˆØµÙŠØ©:** Ø¥Ù…Ø§ ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø£Ùˆ ØªØºÙŠÙŠØ± Ø§Ù„Ù€ logic:

```sql
-- âœ… Ø§Ù„Ø®ÙŠØ§Ø± 1: Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙˆØ¬Ø¨Ø© ÙÙ‚Ø·:
where fare_amount < 0

-- âœ… Ø§Ù„Ø®ÙŠØ§Ø± 2: Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡ refunds Ø§Ù„Ù…Ø¹Ù‚ÙˆÙ„Ø©:
where fare_amount < -50  -- Ù…Ø¹ ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ assert_reasonable_fares.sql
```

---

## ğŸ³ Ù…Ø´Ø§ÙƒÙ„ Docker ÙˆØ§Ù„ØªØ´ØºÙŠÙ„

### âŒ Ù…Ø´ÙƒÙ„Ø© 1: Ù…Ù„Ù `taxi_zone_lookup.csv` Ù…ÙÙ‚ÙˆØ¯ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø¯

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** Ø§Ù„Ù€ dashboard ÙŠØ­ØªØ§Ø¬ Ù…Ù„Ù `streaming/dashboard/data/taxi_zone_lookup.csv` Ù„ÙƒÙ† Ù‚Ø¯ Ù„Ø§ ÙŠÙƒÙˆÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ Ø¹Ù†Ø¯ clone

**Ø§Ù„Ø¥ØµÙ„Ø§Ø­:** Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù€ repositoryØŒ Ø£Ùˆ Ø¥Ø¶Ø§ÙØ© fallback:

```python
# ÙÙŠ zone_lookup.py - Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ Ø¬ÙŠØ¯ Ù„ÙƒÙ† ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡:
try:
    self.df = pd.read_csv(data_path)
    self.zones = dict(zip(self.df['LocationID'], self.df['Zone']))
except FileNotFoundError:
    logger.warning("taxi_zone_lookup.csv not found, using empty zone lookup")
    self.zones = {}
```

---

### âŒ Ù…Ø´ÙƒÙ„Ø© 2: Spark image build Ù‚Ø¯ ÙŠÙØ´Ù„

**Ø§Ù„Ù…Ù„Ù:** `streaming/spark/Dockerfile`

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** Ø§Ø³ØªØ®Ø¯Ø§Ù… pip3 install Ù…Ø¨Ø§Ø´Ø±Ø© Ù‚Ø¯ ÙŠÙØ´Ù„ Ø¨Ø³Ø¨Ø¨ Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ù€ packages

```dockerfile
# âŒ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ:
RUN apt-get update && apt-get install -y python3-pip && \
    pip3 install --no-cache-dir \
    redis==7.1.0 \
    pandas==2.3.3 \
    pyarrow==22.0.0 \  # â† Ù‡Ø°Ø§ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ù‚Ø¯ Ù„Ø§ ÙŠÙƒÙˆÙ† Ù…ØªÙˆÙØ±Ø§Ù‹!
    kafka-python-ng==2.2.3
```

**Ø§Ù„Ø¥ØµÙ„Ø§Ø­:** Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥ØµØ¯Ø§Ø±Ø§Øª Ù…Ø±Ù†Ø©:

```dockerfile
# âœ… Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…Ø­Ø³Ù†:
RUN apt-get update && apt-get install -y python3-pip && \
    pip3 install --no-cache-dir \
    redis>=5.0.0 \
    pandas>=2.0.0 \
    pyarrow>=14.0.0 \
    kafka-python-ng>=2.2.0
```

---

### âŒ Ù…Ø´ÙƒÙ„Ø© 3: Docker Compose Ù‚Ø¯ Ù„Ø§ ÙŠØ¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ images Ø£ÙˆÙ„Ø§Ù‹

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** Ø§Ù„Ù€ services Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… `build:` ØªØ­ØªØ§Ø¬ build Ù‚Ø¨Ù„ Ø§Ù„ØªØ´ØºÙŠÙ„

**Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©:**
```bash
cd streaming/docker
docker compose build    # â† Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ù…Ù‡Ù…Ø©!
docker compose up -d
```

---

### âŒ Ù…Ø´ÙƒÙ„Ø© 4: Spark job Ù‚Ø¯ ÙŠÙØ´Ù„ Ø¨Ø³Ø¨Ø¨ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ù€ packages

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** Ø§Ù„Ù€ spark-submit ÙŠØ­ØªØ§Ø¬ ØªÙ†Ø²ÙŠÙ„ packages Ù…Ù† Maven ÙˆÙ‚Ø¯ ÙŠÙØ´Ù„

```yaml
# ÙÙŠ docker-compose.yml:
command: >
  /opt/spark/bin/spark-submit
  --master spark://spark-master:7077
  --packages org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.1  # â† Ù‚Ø¯ ÙŠÙØ´Ù„ Ø§Ù„ØªÙ†Ø²ÙŠÙ„
```

**Ø§Ù„Ø¥ØµÙ„Ø§Ø­:** Ø¥Ø¶Ø§ÙØ© ivy cache Ù…Ø´ØªØ±ÙƒØ© Ø£Ùˆ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù€ packages Ù…Ø³Ø¨Ù‚Ø§Ù‹ ÙÙŠ Ø§Ù„Ù€ Dockerfile

---

### âŒ Ù…Ø´ÙƒÙ„Ø© 5: Port conflicts

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** Ø§Ù„Ù…Ù†Ø§ÙØ° Ø§Ù„ØªØ§Ù„ÙŠØ© Ù‚Ø¯ ØªÙƒÙˆÙ† Ù…Ø³ØªØ®Ø¯Ù…Ø©:
- 9092 (Kafka)
- 8000 (FastAPI) 
- 8501 (Streamlit)
- 6379 (Redis)
- 8085 (Kafka UI)

**Ø§Ù„Ø¥ØµÙ„Ø§Ø­:** ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù†Ø§ÙØ° Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù‚Ø¨Ù„ Ø§Ù„ØªØ´ØºÙŠÙ„:
```bash
# Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù†Ø§ÙØ° Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©:
sudo lsof -i -P -n | grep LISTEN | grep -E '(9092|8000|8501|6379|8085)'
```

---

### âŒ Ù…Ø´ÙƒÙ„Ø© 6: Redis data persistence

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:** Ø¹Ù†Ø¯ Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ù€ containersØŒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªÙØ­ÙØ¸ ÙÙŠ volumes Ù„ÙƒÙ† Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø³Ø­Ù‡Ø§ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±

**Ø§Ù„Ø¥ØµÙ„Ø§Ø­:** Ù„Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
```bash
# Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 1: Ù…Ù† Dashboard
# Ø§Ø³ØªØ®Ø¯Ù… Ø²Ø± "Clear Redis Data (FLUSH)" ÙÙŠ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

# Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 2: Ù…Ù† Terminal
docker exec redis redis-cli FLUSHALL

# Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 3: Ø­Ø°Ù volumes ÙƒØ§Ù…Ù„Ø©
docker compose down -v
docker compose up -d
```

---

## ğŸš€ Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„

### Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø¯ (Ø²Ù…ÙŠÙ„ØªÙƒ)

#### Ø§Ù„Ø®Ø·ÙˆØ© 1: Clone Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
```bash
git clone https://github.com/abdulrahman532/nyc-taxi-data-pipeline.git
cd nyc-taxi-data-pipeline
```

#### Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª
```bash
# Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Docker
docker --version
docker compose version

# Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø© (ÙŠØ­ØªØ§Ø¬ 8GB+)
free -h
```

#### Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù†Ø§ÙØ°
```bash
# ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ù…Ù†Ø§ÙØ° Ø§Ù„ØªØ§Ù„ÙŠØ© ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…Ø©:
# 6379, 7077, 8000, 8080, 8081, 8082, 8085, 8501, 9092

# Ù„Ù„ØªØ­Ù‚Ù‚:
sudo lsof -i -P -n | grep LISTEN | grep -E '(9092|8000|8501|6379|8085|8080|8081|8082|7077)'
```

#### Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø¨Ù†Ø§Ø¡ ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
```bash
cd streaming/docker

# Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ images (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹!)
docker compose build

# ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
docker compose up -d

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª
docker compose ps
```

#### Ø§Ù„Ø®Ø·ÙˆØ© 5: Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø¯Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
```bash
# Ø§Ù†ØªØ¸Ø± Ø­ÙˆØ§Ù„ÙŠ 60-90 Ø«Ø§Ù†ÙŠØ© Ø­ØªÙ‰ ØªØ¨Ø¯Ø£ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
# ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù€ logs:
docker compose logs -f

# Ø£Ùˆ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø®Ø¯Ù…Ø© Ù…Ø¹ÙŠÙ†Ø©:
docker compose logs -f spark-job
```

#### Ø§Ù„Ø®Ø·ÙˆØ© 6: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ù…Ù„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
```bash
# 1. ØªØ­Ù‚Ù‚ Ù…Ù† FastAPI
curl http://localhost:8000/health

# 2. ØªØ­Ù‚Ù‚ Ù…Ù† Redis
docker exec redis redis-cli ping

# 3. ØªØ­Ù‚Ù‚ Ù…Ù† Kafka
docker exec kafka /opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list
```

#### Ø§Ù„Ø®Ø·ÙˆØ© 7: ÙØªØ­ Dashboard
```bash
# Ø§ÙØªØ­ Ø§Ù„Ù…ØªØµÙØ­ Ø¹Ù„Ù‰:
# http://localhost:8501
```

#### Ø§Ù„Ø®Ø·ÙˆØ© 8: Ø¥Ø±Ø³Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©
```bash
# Ø¥Ø±Ø³Ø§Ù„ Ø±Ø­Ù„Ø© ÙˆØ§Ø­Ø¯Ø© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±:
curl -X POST http://localhost:8000/api/v1/trips \
  -H "Content-Type: application/json" \
  -d '{
    "VendorID": 1,
    "tpep_pickup_datetime": "2025-12-01T10:30:00",
    "tpep_dropoff_datetime": "2025-12-01T10:45:00",
    "passenger_count": 2,
    "trip_distance": 3.5,
    "PULocationID": 161,
    "DOLocationID": 234,
    "payment_type": 1,
    "fare_amount": 15.50,
    "tip_amount": 3.00,
    "total_amount": 20.30
  }'
```

---

### Ø­Ù„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©

#### Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: "Cannot connect to Docker daemon"
```bash
# ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Docker ÙŠØ¹Ù…Ù„:
sudo systemctl start docker
sudo systemctl enable docker

# Ø£Ø¶Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© docker:
sudo usermod -aG docker $USER
# Ø«Ù… Ø£Ø¹Ø¯ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„
```

#### Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: "Port already in use"
```bash
# Ø§Ø¹Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ù†ÙØ°:
sudo lsof -i :8000  # Ù…Ø«Ø§Ù„ Ù„Ù„Ù…Ù†ÙØ° 8000

# Ø£ÙˆÙ‚Ù Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:
sudo kill -9 <PID>
```

#### Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: "Out of memory"
```bash
# Ù‚Ù„Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙÙŠ docker-compose.yml
# Ø£Ùˆ Ø£ÙˆÙ‚Ù Ø¨Ø¹Ø¶ Ø§Ù„Ø®Ø¯Ù…Ø§Øª ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©:
docker compose stop kafka-ui  # Ù…Ø«Ù„Ø§Ù‹
```

#### Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: "Spark job keeps restarting"
```bash
# ØªØ­Ù‚Ù‚ Ù…Ù† logs:
docker compose logs spark-job

# Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©: Kafka topic ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯
# Ø§Ù„Ø­Ù„: Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ÙŠØ¨Ø¯Ø£ Kafka Ø£ÙˆÙ„Ø§Ù‹
# Ø£Ùˆ Ø£Ù†Ø´Ø¦ Ø§Ù„Ù€ topic ÙŠØ¯ÙˆÙŠØ§Ù‹:
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --create --topic nyc.taxi.trips.raw \
  --bootstrap-server localhost:9092 \
  --partitions 3 --replication-factor 1
```

#### Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: "Dashboard shows no data"
```bash
# 1. ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ø±Ø³Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª:
curl -X POST http://localhost:8000/api/v1/trips ...

# 2. ØªØ­Ù‚Ù‚ Ù…Ù† Redis:
docker exec redis redis-cli keys "*"

# 3. Ø§Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙˆØ£Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©:
docker exec redis redis-cli FLUSHALL
```

#### Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: "Build failed"
```bash
# Ø£Ø¹Ø¯ Ø¨Ù†Ø§Ø¡ Ø¨Ø¯ÙˆÙ† cache:
docker compose build --no-cache

# Ø£Ùˆ Ø§Ø¨Ù†ÙŠ ØµÙˆØ±Ø© Ù…Ø¹ÙŠÙ†Ø©:
docker compose build --no-cache spark-job
```

---

### Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø´Ø±ÙˆØ¹

```bash
# Ø¥ÙŠÙ‚Ø§Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª:
docker compose down

# Ø¥ÙŠÙ‚Ø§Ù Ù…Ø¹ Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
docker compose down -v

# Ø¥ÙŠÙ‚Ø§Ù Ù…Ø¹ Ø­Ø°Ù ÙƒÙ„ Ø´ÙŠØ¡ (images Ø£ÙŠØ¶Ø§Ù‹):
docker compose down -v --rmi all
```

---

### Ø±ÙˆØ§Ø¨Ø· Ù…ÙÙŠØ¯Ø©

| Ø§Ù„Ø®Ø¯Ù…Ø© | Ø§Ù„Ø±Ø§Ø¨Ø· | Ø§Ù„ÙˆØµÙ |
|--------|--------|-------|
| Dashboard | http://localhost:8501 | ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© |
| API Docs | http://localhost:8000/docs | ØªÙˆØ«ÙŠÙ‚ Ø§Ù„Ù€ API |
| API Health | http://localhost:8000/health | ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù€ API |
| Kafka UI | http://localhost:8085 | ÙˆØ§Ø¬Ù‡Ø© Ø¥Ø¯Ø§Ø±Ø© Kafka |
| Spark Master | http://localhost:8081 | ÙˆØ§Ø¬Ù‡Ø© Spark |

---

## âœ… Ù…Ù„Ø®Øµ Ø§Ù„Ø¥ØµÙ„Ø§Ø­Ø§Øª

### Ù…Ù„ÙØ§Øª SQL ØªÙ… Ø¥ØµÙ„Ø§Ø­Ù‡Ø§: âœ…

| Ø§Ù„Ù…Ù„Ù | Ù†ÙˆØ¹ Ø§Ù„Ø®Ø·Ø£ | Ø§Ù„Ø­Ø§Ù„Ø© |
|-------|----------|--------|
| `insight_zone_heatmap.sql` | Syntax Error (Ù‚ÙˆØ³ Ù…ÙÙ‚ÙˆØ¯) | âœ… ØªÙ… Ø§Ù„Ø¥ØµÙ„Ø§Ø­ |
| `stg_trips.sql` | Logic Error (Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª) | âœ… ØªÙ… Ø§Ù„Ø¥ØµÙ„Ø§Ø­ |
| `int_trips_validated.sql` | Logic Error (WHERE clause + speed_mph) | âœ… ØªÙ… Ø§Ù„Ø¥ØµÙ„Ø§Ø­ |
| `fct_trips.sql` | Missing Columns | âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© |
| `agg_yearly.sql` | Missing Columns (airport_trips, trips_yoy_pct) | âœ… ØªÙ… Ø§Ù„Ø¥ØµÙ„Ø§Ø­ |
| `agg_monthly.sql` | Missing Columns (fee revenues) | âœ… ØªÙ… Ø§Ù„Ø¥ØµÙ„Ø§Ø­ |

### Ù…Ù„ÙØ§Øª Docker - Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø¯:

| Ø§Ù„Ù…Ù„Ù | Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø© | Ø§Ù„Ø­Ù„ |
|-------|----------|------|
| `Dockerfile` (spark) | Package versions Ù‚Ø¯ ØªØªØºÙŠØ± | ØªÙ… Ø§Ù„ØªÙˆØ«ÙŠÙ‚ |
| `docker-compose.yml` | ÙŠØ­ØªØ§Ø¬ build Ù‚Ø¨Ù„ up | `docker compose build` Ø«Ù… `docker compose up -d` |

---

## ğŸ“ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„ØªÙŠ ØªÙ…Øª

1. **Ø¥ØµÙ„Ø§Ø­ Ø®Ø·Ø£ Syntax ÙÙŠ `insight_zone_heatmap.sql`**
   - ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù‚ÙˆØ³ Ø§Ù„Ù…ØºÙ„Ù‚ ÙˆØ§Ù„Ù€ `desc` ÙÙŠ Ø§Ù„Ù€ CASE statement

2. **Ø¥ØµÙ„Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ `stg_trips.sql`**
   - ØªÙ… ØªØ­ÙˆÙŠÙ„ `dropoff_datetime_raw` Ø¥Ù„Ù‰ bigint Ù…Ø«Ù„ `pickup_datetime_raw`

3. **Ø¥ØµÙ„Ø§Ø­ WHERE clause ÙÙŠ `int_trips_validated.sql`**
   - ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… `pickup_datetime_raw` Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† `pickup_datetime`
   - ØªÙ… Ø¥ØµÙ„Ø§Ø­ Ø­Ø³Ø§Ø¨ `speed_mph` Ù„ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±

4. **Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø© Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ `fct_trips.sql`**
   - `pickup_month`, `pickup_year`, `speed_mph`, `fare_per_mile`
   - `tip_percentage`, `time_of_day`, `day_type`
   - Ø¬Ù…ÙŠØ¹ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù€ flags

5. **Ø¥ØµÙ„Ø§Ø­ `agg_yearly.sql`**
   - Ø¥Ø¶Ø§ÙØ© `airport_trips`
   - Ø¥Ø¶Ø§ÙØ© `trips_yoy_pct` (Year-over-Year)

6. **Ø¥ØµÙ„Ø§Ø­ `agg_monthly.sql`**
   - Ø¥Ø¶Ø§ÙØ© `congestion_revenue`, `airport_fee_revenue`, `cbd_fee_revenue`

---

*ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¨ÙˆØ§Ø³Ø·Ø© GitHub Copilot - 1 Ø¯ÙŠØ³Ù…Ø¨Ø± 2025*
*Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«: Ø¨Ø¹Ø¯ Ø¥ØµÙ„Ø§Ø­ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡*
